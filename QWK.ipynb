{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "https://www.kaggle.com/aroraaman/quadratic-kappa-metric-explained-in-5-simple-steps\n",
    "\n",
    "http://kagglesolutions.com/r/evaluation-metrics--quadratic-weighted-kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./asap-aes/training_set_rel3.tsv\", sep='\\t', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set[train_set['essay_set'] == 2]  # filter for set 2\n",
    "train_set = train_set.reset_index() # resets index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['essay'] = [entry.lower() for entry in train_set['essay']] # lower case for all words in essay\n",
    "train_set[\"essay\"] = [word_tokenize(entry) for entry in train_set[\"essay\"]] # break paragraphs string into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.drop(train_set.columns[0], axis=1, inplace=True) # removes old index\n",
    "train_set.drop(train_set.columns[10:], axis=1, inplace=True) # filter only domain 1 scores\n",
    "train_set.drop(train_set.columns[5], axis=1, inplace=True) # removes rater3_domain1 (NaN for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['avg_score'] = (train_set['rater1_domain1'] + train_set['rater2_domain1']) / 2 # calculate average score\n",
    "train_set['avg_score'] = train_set['avg_score'].apply(np.ceil).astype(int) # round off average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['avg_score2'] = (train_set['rater1_domain2'] + train_set['rater2_domain2']) / 2 # calculate average score\n",
    "train_set['avg_score2'] = train_set['avg_score2'].apply(np.ceil).astype(int) # round off average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['avg_score3'] = (train_set['domain1_score'] + train_set['domain2_score']) / 2 # calculate average score\n",
    "train_set['avg_score3'] = train_set['avg_score3'].apply(np.ceil).astype(int) # round off average score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "avg_score: average score of rater1_domain1 and rater2_domain1 (i.e., average scores of domain1)\n",
    "\n",
    "avg_score2: average score of rater1_domain2 and rater2_domain2 (i.e., average scores of domain2) \n",
    "\n",
    "avg_score3: average score of domain1_score and domain2_score (i.e., average scores of the resolved scores of both domain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "for index, entry in enumerate(train_set['essay']):\n",
    "    final_words = []\n",
    "    word_lemmatized = WordNetLemmatizer()\n",
    "    \n",
    "    for word, tag in pos_tag(entry):\n",
    "        if word not in stopwords.words(\"english\") and word.isalpha():\n",
    "            word_final = word_lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "            final_words.append(word_final)\n",
    "\n",
    "    train_set.loc[index, \"essay_final\"] = str(final_words)\n",
    "train_set.drop(train_set.columns[2], axis=1, inplace=True) # removes the original essay column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be tested:\n",
    "the model selection code run as follow: model_selection.train_test_split(train_set['essay_final'], train_set['domain1_score'], test_size=0.3)\n",
    "\n",
    "Replace 'domain1_score' with \"avg_score\", \"avg_score2\", \"avg_score3\" for further testing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into training and testing set\n",
    "train_essay, test_essay, train_label, test_label = model_selection.train_test_split(train_set['essay_final'], train_set['avg_score3'], test_size=0.3)\n",
    "\n",
    "# transform the avg score into label of 0,1,2,3....\n",
    "Encoder = LabelEncoder()\n",
    "train_label = Encoder.fit_transform(train_label)\n",
    "test_label = Encoder.transform(test_label)\n",
    "\n",
    "# transform essay into matrix\n",
    "Tfidf_vect = TfidfVectorizer()\n",
    "Tfidf_vect.fit(train_set[\"essay_final\"])\n",
    "train_essay_vect = Tfidf_vect.transform(train_essay)\n",
    "test_essay_vect = Tfidf_vect.transform(test_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   2   0]\n",
      " [  0   0   2  28   0]\n",
      " [  0   0   2 180   0]\n",
      " [  0   0   0 294   0]\n",
      " [  0   0   0  32   0]]\n"
     ]
    }
   ],
   "source": [
    "# fitting training set into naive bayes\n",
    "naive = naive_bayes.MultinomialNB()\n",
    "naive.fit(train_essay_vect, train_label)\n",
    "\n",
    "# fitting testing set on NB classifier\n",
    "predictions_NB = naive.predict(test_essay_vect)\n",
    "\n",
    "# producing confusion matrix\n",
    "O = confusion_matrix(test_label, predictions_NB)\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros((N,N)); w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (N-1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        w[i][j] = float(((i-j)**2)/d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_hist=np.zeros([N])\n",
    "for item in test_label: \n",
    "    act_hist[item]+=1\n",
    "    \n",
    "pred_hist=np.zeros([N])\n",
    "for item in predictions_NB: \n",
    "    pred_hist[item]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.00000e+00, 0.00000e+00, 8.00000e+00, 1.07200e+03, 0.00000e+00],\n",
       "       [0.00000e+00, 0.00000e+00, 1.20000e+02, 1.60800e+04, 0.00000e+00],\n",
       "       [0.00000e+00, 0.00000e+00, 7.28000e+02, 9.75520e+04, 0.00000e+00],\n",
       "       [0.00000e+00, 0.00000e+00, 1.17600e+03, 1.57584e+05, 0.00000e+00],\n",
       "       [0.00000e+00, 0.00000e+00, 1.28000e+02, 1.71520e+04, 0.00000e+00]])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = np.outer(act_hist, pred_hist); E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = E/E.sum(); E.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999999999999999"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = O/O.sum(); O.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024943310657596474"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=0\n",
    "den=0\n",
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        num+=w[i][j]*O[i][j]\n",
    "        den+=w[i][j]*E[i][j]\n",
    "        \n",
    "weighted_kappa = (1 - (num/den))\n",
    "weighted_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ignore these at the moment\n",
    "\n",
    "# Set 2\n",
    "Domain 1 score:<br>\n",
    "0.17861887795156706<br>\n",
    "0.8213811220484329\n",
    "\n",
    "Domain 2 score: <br>\n",
    "0.1041177197972053<br>\n",
    "0.8958822802027947\n",
    "\n",
    "Avarage of domain 1 and domain 2 score: <br>\n",
    "0.010827339513058365<br>\n",
    "0.9891726604869416\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set 5\n",
    "\n",
    "Domain 1 score:<br>\n",
    "0.354743571530047<br>\n",
    "0.645256428469953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
