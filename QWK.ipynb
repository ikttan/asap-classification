{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reference \n",
    "https://www.kaggle.com/aroraaman/quadratic-kappa-metric-explained-in-5-simple-steps\n",
    "\n",
    "http://kagglesolutions.com/r/evaluation-metrics--quadratic-weighted-kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from collections import defaultdict\n",
    "from nltk.corpus import wordnet as wn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = pd.read_csv(\"./asap-aes/training_set_rel3.tsv\", sep='\\t', encoding=\"latin-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = train_set[train_set['essay_set'] == 2]  # filter for set 2\n",
    "train_set = train_set.reset_index() # resets index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['essay'] = [entry.lower() for entry in train_set['essay']] # lower case for all words in essay\n",
    "train_set[\"essay\"] = [word_tokenize(entry) for entry in train_set[\"essay\"]] # break paragraphs string into tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set.drop(train_set.columns[0], axis=1, inplace=True) # removes old index\n",
    "train_set.drop(train_set.columns[10:], axis=1, inplace=True) # filter only domain 1 scores\n",
    "train_set.drop(train_set.columns[5], axis=1, inplace=True) # removes rater3_domain1 (NaN for all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['avg_score'] = (train_set['rater1_domain1'] + train_set['rater2_domain1']) / 2 # calculate average score\n",
    "train_set['avg_score'] = train_set['avg_score'].apply(np.ceil).astype(int) # round off average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['avg_score2'] = (train_set['rater1_domain2'] + train_set['rater2_domain2']) / 2 # calculate average score\n",
    "train_set['avg_score2'] = train_set['avg_score2'].apply(np.ceil).astype(int) # round off average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set['avg_score3'] = (train_set['domain1_score'] + train_set['domain2_score']) / 2 # calculate average score\n",
    "train_set['avg_score3'] = train_set['avg_score3'].apply(np.ceil).astype(int) # round off average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Description\n",
    "\n",
    "avg_score: average score of rater1_domain1 and rater2_domain1 (i.e., average scores of domain1)\n",
    "\n",
    "avg_score2: average score of rater1_domain2 and rater2_domain2 (i.e., average scores of domain2) \n",
    "\n",
    "avg_score3: average score of domain1_score and domain2_score (i.e., average scores of the resolved scores of both domain) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "np.random.seed(500)\n",
    "tag_map = defaultdict(lambda: wn.NOUN)\n",
    "tag_map['J'] = wn.ADJ\n",
    "tag_map['V'] = wn.VERB\n",
    "tag_map['R'] = wn.ADV\n",
    "\n",
    "for index, entry in enumerate(train_set['essay']):\n",
    "    final_words = []\n",
    "    word_lemmatized = WordNetLemmatizer()\n",
    "    \n",
    "    for word, tag in pos_tag(entry):\n",
    "        if word not in stopwords.words(\"english\") and word.isalpha():\n",
    "            word_final = word_lemmatized.lemmatize(word, tag_map[tag[0]])\n",
    "            final_words.append(word_final)\n",
    "\n",
    "    train_set.loc[index, \"essay_final\"] = str(final_words)\n",
    "train_set.drop(train_set.columns[2], axis=1, inplace=True) # removes the original essay column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To be tested:\n",
    "the model selection code run as follow: model_selection.train_test_split(train_set['essay_final'], train_set['domain1_score'], test_size=0.3)\n",
    "\n",
    "Replace 'domain1_score' with \"avg_score\", \"avg_score2\", \"avg_score3\" for further testing\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "real_label = Encoder.fit_transform(train_set['domain1_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "Tfidf_vect = TfidfVectorizer()\n",
    "Tfidf_vect.fit(train_set['essay_final'])\n",
    "train_essay_vect = Tfidf_vect.transform(train_set['essay_final'])\n",
    "test_essay_vect = Tfidf_vect.transform(train_set['essay_final'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1800x11252 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 168788 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_essay_vect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive = naive_bayes.MultinomialNB()\n",
    "naive.fit(train_essay_vect, real_label)\n",
    "\n",
    "predictions_NB = naive.predict(test_essay_vect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   0   0   0   0  10   0   0   0   0]\n",
      " [  0   0   0   0   0   0   1   0   0   0   0]\n",
      " [  0   0   0   0   0   0  17   0   0   0   0]\n",
      " [  0   0   0   0   0   0  17   0   0   0   0]\n",
      " [  0   0   0   0   0   0 110   0   0   0   0]\n",
      " [  0   0   0   0   0   0 135   0   0   0   0]\n",
      " [  0   0   0   0   0   0 687   0   0   0   0]\n",
      " [  0   0   0   0   0   0 334   0   0   0   0]\n",
      " [  0   0   0   0   0   0 316   0   0   0   0]\n",
      " [  0   0   0   0   0   0 109   0   0   0   0]\n",
      " [  0   0   0   0   0   0  47   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "O = confusion_matrix(real_label, predictions_NB)\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros((N,N)); w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (N-1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        w[i][j] = float(((i-j)**2)/d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_label.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_NB.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_NB.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_hist=np.zeros([N])\n",
    "for item in real_label: \n",
    "    act_hist[item]+=1\n",
    "    \n",
    "pred_hist=np.zeros([N])\n",
    "for item in predictions_NB: \n",
    "    pred_hist[item]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "          17830.,       0.,       0.,       0.,       0.],\n",
       "       [      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "           1783.,       0.,       0.,       0.,       0.],\n",
       "       [      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "          30311.,       0.,       0.,       0.,       0.],\n",
       "       [      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "          30311.,       0.,       0.,       0.,       0.],\n",
       "       [      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "         196130.,       0.,       0.,       0.,       0.],\n",
       "       [      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "         240705.,       0.,       0.,       0.,       0.],\n",
       "       [      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "        1224921.,       0.,       0.,       0.,       0.],\n",
       "       [      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "         595522.,       0.,       0.,       0.,       0.],\n",
       "       [      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "         563428.,       0.,       0.,       0.,       0.],\n",
       "       [      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "         194347.,       0.,       0.,       0.,       0.],\n",
       "       [      0.,       0.,       0.,       0.,       0.,       0.,\n",
       "          83801.,       0.,       0.,       0.,       0.]])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = np.outer(act_hist, pred_hist); E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = E/E.sum(); E.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = O/O.sum(); O.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=0\n",
    "den=0\n",
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        num+=w[i][j]*O[i][j]\n",
    "        den+=w[i][j]*E[i][j]\n",
    "            \n",
    "weighted_kappa = (1 - (num/den))\n",
    "weighted_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting into training and testing set\n",
    "train_essay, test_essay, train_label, test_label = model_selection.train_test_split(train_set['essay_final'], train_set['domain1_score'], test_size=0.3)\n",
    "\n",
    "# transform the avg score into label of 0,1,2,3....\n",
    "Encoder = LabelEncoder()\n",
    "train_label = Encoder.fit_transform(train_label)\n",
    "test_label = Encoder.transform(test_label)\n",
    "\n",
    "# transform essay into matrix\n",
    "Tfidf_vect = TfidfVectorizer()\n",
    "Tfidf_vect.fit(train_set[\"essay_final\"])\n",
    "train_essay_vect = Tfidf_vect.transform(train_essay)\n",
    "test_essay_vect = Tfidf_vect.transform(test_essay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_label.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0   0   4   2   0   0]\n",
      " [  0   0  25  25   0   0]\n",
      " [  0   0  52 187   0   0]\n",
      " [  0   0   7 209   0   0]\n",
      " [  0   0   1  27   0   0]\n",
      " [  0   0   0   1   0   0]]\n"
     ]
    }
   ],
   "source": [
    "# fitting training set into naive bayes\n",
    "naive = naive_bayes.MultinomialNB()\n",
    "naive.fit(train_essay_vect, train_label)\n",
    "\n",
    "# fitting testing set on NB classifier\n",
    "predictions_NB = naive.predict(test_essay_vect)\n",
    "\n",
    "# producing confusion matrix\n",
    "O = confusion_matrix(test_label, predictions_NB)\n",
    "print(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(O)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.zeros((N,N)); w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = (N-1)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        w[i][j] = float(((i-j)**2)/d) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "act_hist=np.zeros([N])\n",
    "for item in test_label: \n",
    "    act_hist[item]+=1\n",
    "    \n",
    "pred_hist=np.zeros([N])\n",
    "for item in predictions_NB: \n",
    "    pred_hist[item]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[     0.,      0.,    497.,   3283.,      0.,      0.],\n",
       "       [     0.,      0.,   2627.,  17353.,      0.,      0.],\n",
       "       [     0.,      0.,  17111., 113029.,      0.,      0.],\n",
       "       [     0.,      0.,  15691., 103649.,      0.,      0.],\n",
       "       [     0.,      0.,   2130.,  14070.,      0.,      0.],\n",
       "       [     0.,      0.,    284.,   1876.,      0.,      0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = np.outer(act_hist, pred_hist); E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = E/E.sum(); E.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "O = O/O.sum(); O.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.17861887795156706"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num=0\n",
    "den=0\n",
    "for i in range(len(w)):\n",
    "    for j in range(len(w)):\n",
    "        num+=w[i][j]*O[i][j]\n",
    "        den+=w[i][j]*E[i][j]\n",
    "        \n",
    "weighted_kappa = (1 - (num/den))\n",
    "weighted_kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Ignore these at the moment\n",
    "\n",
    "# Set 2\n",
    "Domain 1 score:<br>\n",
    "0.17861887795156706<br>\n",
    "0.8213811220484329\n",
    "\n",
    "Domain 2 score: <br>\n",
    "0.1041177197972053<br>\n",
    "0.8958822802027947\n",
    "\n",
    "Avarage of domain 1 and domain 2 score: <br>\n",
    "0.010827339513058365<br>\n",
    "0.9891726604869416\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set 5\n",
    "\n",
    "Domain 1 score:<br>\n",
    "0.354743571530047<br>\n",
    "0.645256428469953"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
